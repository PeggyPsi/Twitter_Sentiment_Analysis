{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific file is used to create vectors/feautures for each tweet\n",
    "for both train and test data based on the embeddings of vocabulary words\n",
    "that were produced with Word2Vec method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "#Word Embeddings\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....................................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA (Word Embedded Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train dataset\n",
    "def load_data(file, col_names, n=0):\n",
    "    #Read all data\n",
    "    if n==0:\n",
    "        data = pd.read_csv(file, sep=\"\\t\", header=None, names=col_names, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "    #Read specific number of rows of data\n",
    "    else:\n",
    "        data = pd.read_csv(file, nrows=n, sep=\"\\t\", header=None, names=col_names, quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve cleaned up tweets for further usage\n",
    "train_tweets_cleaned = pd.read_pickle(\"./train_tweets_cleaned.pkl\")\n",
    "test_tweets_cleaned = pd.read_pickle(\"./test_tweets_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THIS ACCORDINGLY\n",
    "# vector_size = 50\n",
    "# vector_size = 100\n",
    "# vector_size = 200\n",
    "vector_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = Word2Vec.load(\"./train_tweets_word2vec_vs\"+str(vector_size)+\".pkl\")\n",
    "vocabulary_train = list(model_train.wv.vocab)\n",
    "model_test = Word2Vec.load(\"./test_tweets_word2vec_vs\"+str(vector_size)+\".pkl\")\n",
    "vocabulary_test = list(model_test.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Extra Features\n",
    "train_extra_features = pd.read_pickle(\"./train_extra_vs\"+str(vector_size)+\".pkl\")\n",
    "test_extra_features = pd.read_pickle(\"./test_extra_vs\"+str(vector_size)+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....................................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEETS EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default vector for words that have not been vectorized\n",
    "# Σ<vectored_words>/<num_vectored_words>\n",
    "def DefaultVector(model, vocabulary):\n",
    "    default_vector = np.zeros(vector_size)\n",
    "    for word in vocabulary:\n",
    "        default_vector = np.add(default_vector, model.wv[word])\n",
    "    return default_vector/len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectors for each tweet\n",
    "def Tweet2Vector(tweet, model, vocabulary):\n",
    "    tweet_vector = np.zeros(vector_size)\n",
    "    non_vectored_words = 0\n",
    "    \n",
    "    # Traverse through each word of the tweet\n",
    "    for word in tweet:\n",
    "        #Search word in vocabulary\n",
    "        if word in vocabulary:\n",
    "            tweet_vector = np.add(tweet_vector, model.wv[word])\n",
    "        else:\n",
    "            non_vectored_words = non_vectored_words + 1\n",
    "        \n",
    "    # If there are words that have been not vectorized\n",
    "    # for each one of them create a vector equal to Σ<vectored_words>/<num_vectored_words>\n",
    "    tweet_vector = np.add(tweet_vector, non_vectored_words*default_vector)\n",
    "    return tweet_vector\n",
    "\n",
    "# Tweet2Vector(train_tweets_cleaned.at[0,'Tweet'], model_train, vocabulary_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe with the vectorized tweets and more of their information\n",
    "def Modeled_Tweets(col_names, cleaned_tweets, model, vocabulary):\n",
    "    # Create new dataframe for vectorized tweets\n",
    "    tweets_modeled = pd.DataFrame()\n",
    "    tweets_modeled = cleaned_tweets[col_names].copy()\n",
    "    # Create vectors for each tweet\n",
    "    tweets_modeled['Vector'] = cleaned_tweets['Tweet'].apply(lambda tweet: Tweet2Vector(tweet, model, vocabulary))\n",
    "#     tweets_modeled = tweets_modeled[0:5]\n",
    "    return tweets_modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>[gas, hous, hit, go, chapel, hill, sat, :)]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.5317999795079231, -1.3948887214064598, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263405084770172928</td>\n",
       "      <td>[theo, walcott, still, shit, watch, rafa, john...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.4684139392338693, -1.170335978269577, -0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262163168678248449</td>\n",
       "      <td>[gsp, fan, hate, nick, diaz, cant, wait, febru...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.4220394731709353, -1.1228334289729296, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264249301910310912</td>\n",
       "      <td>[iranian, general, say, israel, iron, dome, ca...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[0.4096992301964752, -2.1316297520637213, -1.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262682041215234048</td>\n",
       "      <td>[tehran, mon, amour, obama, tri, establish, ti...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.03934148471325797, -2.473725941169202, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetID                                              Tweet  \\\n",
       "0  264183816548130816        [gas, hous, hit, go, chapel, hill, sat, :)]   \n",
       "1  263405084770172928  [theo, walcott, still, shit, watch, rafa, john...   \n",
       "2  262163168678248449  [gsp, fan, hate, nick, diaz, cant, wait, febru...   \n",
       "3  264249301910310912  [iranian, general, say, israel, iron, dome, ca...   \n",
       "4  262682041215234048  [tehran, mon, amour, obama, tri, establish, ti...   \n",
       "\n",
       "  Sentiment                                             Vector  \n",
       "0  positive  [0.5317999795079231, -1.3948887214064598, -0.9...  \n",
       "1  negative  [0.4684139392338693, -1.170335978269577, -0.70...  \n",
       "2  negative  [0.4220394731709353, -1.1228334289729296, -0.8...  \n",
       "3  negative  [0.4096992301964752, -2.1316297520637213, -1.1...  \n",
       "4   neutral  [-0.03934148471325797, -2.473725941169202, -0....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN TWEETS\n",
    "default_vector = DefaultVector(model_train, vocabulary_train)\n",
    "train_tweets_modeled = Modeled_Tweets(['TweetID', 'Tweet', 'Sentiment'],\n",
    "                                     train_tweets_cleaned,\n",
    "                                     model_train,\n",
    "                                     vocabulary_train)\n",
    "\n",
    "train_tweets_modeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801989080477154944</td>\n",
       "      <td>[ari, ariana, grand, full]</td>\n",
       "      <td>[0.10410167671424628, -0.549238750863187, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801989272341453952</td>\n",
       "      <td>[ariana, grand, kii, fm, truli, cd, listen, pa...</td>\n",
       "      <td>[0.24175302191622494, -1.2834049896243584, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>801990978424962944</td>\n",
       "      <td>[ariana, grand, white, hous, easter, egg, roll...</td>\n",
       "      <td>[0.2684575153855729, -1.078699084150903, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>801996232553963008</td>\n",
       "      <td>[ariana, grand, sweet, like, candi, oz, ml, se...</td>\n",
       "      <td>[0.28051567165781977, -1.56956492425248, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801998343442407040</td>\n",
       "      <td>[side, side]</td>\n",
       "      <td>[0.05338717997074127, -0.30022650957107544, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetID                                              Tweet  \\\n",
       "0  801989080477154944                         [ari, ariana, grand, full]   \n",
       "1  801989272341453952  [ariana, grand, kii, fm, truli, cd, listen, pa...   \n",
       "2  801990978424962944  [ariana, grand, white, hous, easter, egg, roll...   \n",
       "3  801996232553963008  [ariana, grand, sweet, like, candi, oz, ml, se...   \n",
       "4  801998343442407040                                       [side, side]   \n",
       "\n",
       "                                              Vector  \n",
       "0  [0.10410167671424628, -0.549238750863187, -0.0...  \n",
       "1  [0.24175302191622494, -1.2834049896243584, -0....  \n",
       "2  [0.2684575153855729, -1.078699084150903, -0.08...  \n",
       "3  [0.28051567165781977, -1.56956492425248, -0.07...  \n",
       "4  [0.05338717997074127, -0.30022650957107544, -0...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST TWEETS\n",
    "default_vector = DefaultVector(model_test, vocabulary_test)\n",
    "test_tweets_modeled = Modeled_Tweets(['TweetID', 'Tweet'],\n",
    "                                     test_tweets_cleaned,\n",
    "                                     model_test,\n",
    "                                     vocabulary_test)\n",
    "\n",
    "test_tweets_modeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....................................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADD MORE FEAUTURES TO TWEET VECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN DATA\n",
    "for index, row in train_tweets_modeled.iterrows():\n",
    "    tweet = row['Tweet']\n",
    "    vector = row['Vector']\n",
    "    vector = np.append(vector, train_extra_features.loc[index, :].values.tolist())\n",
    "    train_tweets_modeled.at[index, \"Vector\"] = vector\n",
    "    \n",
    "# TEST DATA\n",
    "for index, row in test_tweets_modeled.iterrows():\n",
    "    tweet = row['Tweet']\n",
    "    vector = row['Vector']\n",
    "    vector = np.append(vector, test_extra_features.loc[index, :].values.tolist())\n",
    "    test_tweets_modeled.at[index, \"Vector\"] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ....................................................................................................................................................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorized tweets for later further use\n",
    "train_tweets_modeled.to_pickle(\"./train_tweets_vectorized_Word2Vec_vs\"+str(vector_size)+\".pkl\")\n",
    "test_tweets_modeled.to_pickle(\"./test_tweets_vectorized_Word2Vec_vs\"+str(vector_size)+\".pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
